{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexing import IndexType, InvertedIndex, BasicInvertedIndex, Indexer\n",
    "from document_preprocessor import RegexTokenizer, Doc2QueryAugmenter\n",
    "from relevance import map_score, ndcg_score, run_relevance_tests\n",
    "from ranker import *\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import gzip\n",
    "import os\n",
    "import seaborn as sns                                                                                                                                                                                                            \n",
    "import matplotlib.pyplot as plt                                                                                                                                                                                                  \n",
    "import csv\n",
    "from importlib import reload\n",
    "import l2r\n",
    "from l2r import L2RRanker, L2RFeatureExtractor\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from Document_retriver import L2RRetriever\n",
    "from RAG import RAGSystem\n",
    "from vector_ranker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 543 stopwords\n"
     ]
    }
   ],
   "source": [
    "stopwords = set()\n",
    "\n",
    "with open('stopwords.txt', 'r', encoding='utf-8') as file:                                                                                                                                                                  \n",
    "    for line in file:                                                                                                                                                                                                            \n",
    "        stopwords.add(line.strip().lower())\n",
    "\n",
    "print('Loaded %d stopwords' % len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer = RegexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_type = IndexType.BasicInvertedIndex  # Or PositionalIndex based on your needs\n",
    "dataset_path = 'cleaned_output.jsonl'  # Path to your JSONL file\n",
    "minimum_word_frequency = 0  # Set to control minimum token frequency, 0 to ignore\n",
    "text_key = \"text\"  # The JSON key containing the text content\n",
    "doc_augment_dict = None  # Optional dictionary for additional document queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text = {}\n",
    "doc_dict = {}\n",
    "with open(dataset_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        doc = json.loads(line)\n",
    "        doc_text[doc['ID']] = doc['text']\n",
    "        doc_dict[doc['ID']] = doc['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "models = 'google/flan-t5-base'\n",
    "augmenter = Doc2QueryAugmenter(models)\n",
    "prefix = \"Generate a query for the following text: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.93s/it]\n"
     ]
    }
   ],
   "source": [
    "documents = list(doc_text.values())[:1]\n",
    "for doc in tqdm(documents):\n",
    "    query = augmenter.get_queries(doc, n_queries=10, prefix_prompt=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which item is listed on the list of ingredients and ingredients?',\n",
       " 'Where are the names of the products discussed?',\n",
       " \"What are the names of the ingredients in Healthline's evidence-based skin care ingredient dictionary?\",\n",
       " \"What products are included in Healthline's evidence-based skin care ingredient dictionary?\",\n",
       " 'What is the title of the text?',\n",
       " 'Is it a good idea to buy a dictionary of skin care ingredients?',\n",
       " 'What ingredients are considered to be evidence based?',\n",
       " \"What are the names of Healthline's ingredients in the glossary?\",\n",
       " \"Which website is Healthline's Evidence-Based Skin Care Ingredients Dictionary?\",\n",
       " 'The BD is a medical review. What are the ingredients of this product?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for every file in the jsonl file, we will generate a query with doc id, title, and the query and sacve as csv file\n",
    "# start_line = 2281\n",
    "# with open(dataset_path, 'r', encoding='utf-8') as file:\n",
    "#     for current_line_number, line in enumerate(file, start=0):\n",
    "#         if current_line_number < start_line:\n",
    "#             continue\n",
    "#         doc = json.loads(line)\n",
    "#         doc_id = doc['ID']\n",
    "#         doc_title = doc['Title']\n",
    "#         doc_text = doc['text']\n",
    "#         query = augmenter.get_queries(doc_text, n_queries=10, prefix_prompt=prefix)\n",
    "#         with open('queries.csv', 'a', newline='') as file:\n",
    "#             writer = csv.writer(file)\n",
    "#             for q in query:\n",
    "#                 writer.writerow([doc_id, doc_title, q])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123649/123649 [00:00<00:00, 551736.15it/s]\n"
     ]
    }
   ],
   "source": [
    "DOC2QUERY_PATH = 'queries.csv'\n",
    "doc_augment_dict = defaultdict(lambda: [])\n",
    "with open(DOC2QUERY_PATH, 'r', encoding='utf-8') as file:\n",
    "    dataset = csv.reader(file)\n",
    "    for idx, row in tqdm(enumerate(dataset), total=123649):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        doc_augment_dict[int(row[0])].append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index found. Loading existing index...\n",
      "Index loaded from index\n"
     ]
    }
   ],
   "source": [
    "index_directory_name = 'index'\n",
    "if os.path.exists(index_directory_name):\n",
    "    print(\"Index found. Loading existing index...\")\n",
    "    index = BasicInvertedIndex()\n",
    "    index.load(index_directory_name)\n",
    "    \n",
    "else:\n",
    "    print(\"Index not found. Creating and saving index...\")\n",
    "    index = Indexer.create_index(\n",
    "        index_type=index_type,\n",
    "        dataset_path=dataset_path,\n",
    "        document_preprocessor=Tokenizer,\n",
    "        stopwords=stopwords,\n",
    "        minimum_word_frequency=minimum_word_frequency,\n",
    "        text_key=text_key,\n",
    "        doc_augment_dict=doc_augment_dict\n",
    "    )\n",
    "    index.save(index_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved to index\n"
     ]
    }
   ],
   "source": [
    "index_directory_name = 'index'\n",
    "index.save(index_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_tokens': 1163, 'length': 5938, 'stored_length': 3576}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get meta data about doc 1\n",
    "doc_meta = index.get_doc_metadata(0)\n",
    "doc_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scorer = BM25(\n",
    "    index=index,\n",
    "    parameters={'b': 0.75, 'k1': 1.2, 'k3': 8}\n",
    ")\n",
    "\n",
    "# Initialize Ranker with BM25 scorer\n",
    "ranker = Ranker(\n",
    "    index=index,\n",
    "    document_preprocessor=Tokenizer,\n",
    "    stopwords=stopwords,\n",
    "    scorer=bm25_scorer,\n",
    "    raw_text_dict=doc_dict\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run a query through the Ranker\n",
    "# query = \"Effective treatments for skin conditions\"\n",
    "\n",
    "# ranked_documents = ranker.query(query)\n",
    "\n",
    "# # Display ranked documents and their BM25 scores\n",
    "# for doc_id, score in ranked_documents[:50]:\n",
    "#     print(f\"Document ID: {doc_id}, BM25 Score: {score}\")\n",
    "#     print(doc_dict[doc_id])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_bm25 = run_relevance_tests('ranked_documents.csv', ranker)\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"Mean Average Precision (MAP): {results_bm25['MAP']}\")\n",
    "# print(f\"Normalized Discounted Cumulative Gain (NDCG): {results_bm25['NDCG']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing documents: 12368it [00:00, 17845.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved to Titleindex\n"
     ]
    }
   ],
   "source": [
    "text_key = \"Title\"  # The JSON key containing the text content\n",
    "\n",
    "\n",
    "# Create the index\n",
    "Title_index = Indexer.create_index(\n",
    "    index_type=index_type,\n",
    "    dataset_path=dataset_path,\n",
    "    document_preprocessor=Tokenizer,\n",
    "    stopwords=stopwords,\n",
    "    minimum_word_frequency=minimum_word_frequency,\n",
    "    text_key=text_key,\n",
    "    doc_augment_dict=doc_augment_dict\n",
    ")\n",
    "index_directory_name = 'Titleindex'\n",
    "Title_index.save(index_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bi_encoder_model_name = 'sentence-transformers/all-MiniLM-L6-v2'  # or any other sentence-transformers model\n",
    "biencoder_model = SentenceTransformer(bi_encoder_model_name, device='cpu')\n",
    "\n",
    "documents_list = list(doc_text.values())\n",
    "# Encode the documents once\n",
    "encoded_docs = biencoder_model.encode(documents_list, convert_to_tensor=False)\n",
    "encoded_docs = np.array(encoded_docs)  # Ensure it's a numpy array\n",
    "\n",
    "# Create a mapping from row number to doc ID\n",
    "row_to_docid = list(doc_text.keys())\n",
    "\n",
    "# Initialize VectorRanker\n",
    "vector_ranker = VectorRanker(\n",
    "    bi_encoder_model_name=bi_encoder_model_name,\n",
    "    encoded_docs=encoded_docs,\n",
    "    row_to_docid=row_to_docid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vector_ranker.VectorRanker at 0x3a45653d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 622, number of used features: 9\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the necessary components like document_index, title_index, etc.\n",
    "feature_extractor = L2RFeatureExtractor(\n",
    "    document_index=index,  # The inverted index of document contents\n",
    "    title_index=Title_index,        # The inverted index of document titles\n",
    "    document_preprocessor=Tokenizer,  # Instance of the tokenizer class\n",
    "    stopwords=stopwords                 # Set of stopwords\n",
    ")\n",
    "l2r_ranker = L2RRanker(\n",
    "    document_index=index,\n",
    "    title_index=Title_index,\n",
    "    document_preprocessor=Tokenizer,\n",
    "    stopwords=stopwords,\n",
    "    ranker=vector_ranker,\n",
    "    feature_extractor=feature_extractor\n",
    ")\n",
    "\n",
    "# Train the L2R ranker with relevance data\n",
    "l2r_ranker.train('ranked_documents.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 148, Score: 0.32154217072155816\n",
      "https://www.healthline.com/health/custom-skin-care\n",
      "\n",
      "Document ID: 7222, Score: 0.32154217072155816\n",
      "https://www.healthline.com/health/beauty-skin-care/what-does-your-skin-really-need-how-to-achieve-truly-healthy-skin#keep-it-simple\n",
      "\n",
      "Document ID: 4349, Score: 0.29457445751171457\n",
      "https://www.healthline.com/health/beauty-skin-care/the-ultimate-summer-skin-care-routine-in-8-simple-steps\n",
      "\n",
      "Document ID: 1125, Score: 0.29457445751171457\n",
      "https://www.healthline.com/health/beauty-skin-care/what-does-your-skin-really-need-how-to-achieve-truly-healthy-skin#sun-protection\n",
      "\n",
      "Document ID: 1211, Score: 0.29457445751171457\n",
      "https://www.healthline.com/health/beauty-skin-care/what-does-your-skin-really-need-how-to-achieve-truly-healthy-skin#hydration\n",
      "\n",
      "Document ID: 986, Score: 0.29457445751171457\n",
      "https://www.healthline.com/health/beauty-skin-care/what-does-your-skin-really-need-how-to-achieve-truly-healthy-skin#know-your-skin-type\n",
      "\n",
      "Document ID: 1557, Score: 0.19802198320981731\n",
      "https://www.healthline.com/health/beauty-skin-care/the-ultimate-pared-down-skincare-routine\n",
      "\n",
      "Document ID: 2825, Score: 0.17190310263791292\n",
      "https://www.healthline.com/health/beauty-skin-care/how-to-get-even-skin\n",
      "\n",
      "Document ID: 9709, Score: 0.16650125925865472\n",
      "https://www.healthline.com/health/beauty-skin-care/skin-tightening-treatment#in-office-procedures\n",
      "\n",
      "Document ID: 11518, Score: 0.15493654272199353\n",
      "https://www.healthline.com/health/beauty-skin-care/face-mask-for-acne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Effective treatments for skin conditions\"\n",
    "ranked_documents = l2r_ranker.query(query)\n",
    "# Display top-ranked documents and their scores\n",
    "for doc_id, score in ranked_documents[:10]:\n",
    "    print(f\"Document ID: {doc_id}, Score: {score}\")\n",
    "    print(doc_dict[doc_id])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP): 0.03901098901098901\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.07966750266109551\n"
     ]
    }
   ],
   "source": [
    "results = run_relevance_tests('ranked_documents.csv', l2r_ranker)\n",
    "# Print the results\n",
    "print(f\"Mean Average Precision (MAP): {results['MAP']}\")\n",
    "print(f\"Normalized Discounted Cumulative Gain (NDCG): {results['NDCG']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot the results\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.bar(['BM25', 'L2R'], [results_bm25['MAP'], results['MAP']])\n",
    "# plt.ylabel('Mean Average Precision (MAP)')\n",
    "# plt.title('BM25 vs L2R')\n",
    "# plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.bar(['BM25', 'L2R'], [results_bm25['NDCG'], results['NDCG']])\n",
    "# plt.ylabel('Normalized Discounted Cumulative Gain (NDCG)')\n",
    "# plt.title('BM25 vs L2R')\n",
    "# plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4129, np.float64(0.23464614739350026)),\n",
       " (5664, np.float64(0.23464614739350026)),\n",
       " (4052, np.float64(0.2065058708902234)),\n",
       " (7191, np.float64(0.19162648007714966)),\n",
       " (11671, np.float64(0.19162648007714966)),\n",
       " (11542, np.float64(0.15860758248297863)),\n",
       " (8388, np.float64(0.15254568674778193)),\n",
       " (682, np.float64(0.1351106020217465)),\n",
       " (2898, np.float64(0.12875195617926338)),\n",
       " (10267, np.float64(0.10993917284483876)),\n",
       " (9256, np.float64(0.09484816611055788)),\n",
       " (8360, np.float64(0.0934706593433244)),\n",
       " (9633, np.float64(0.08075272735637218)),\n",
       " (9164, np.float64(0.07412859738081685)),\n",
       " (1877, np.float64(0.06829763546753892)),\n",
       " (8954, np.float64(0.06829763546753892)),\n",
       " (6795, np.float64(0.06829763546753892)),\n",
       " (7325, np.float64(0.06829763546753892)),\n",
       " (10299, np.float64(0.06829763546753892)),\n",
       " (4586, np.float64(0.06829763546753892)),\n",
       " (8144, np.float64(0.06829763546753892)),\n",
       " (8054, np.float64(0.06829763546753892)),\n",
       " (5743, np.float64(0.06829763546753892)),\n",
       " (10133, np.float64(0.06829763546753892)),\n",
       " (9807, np.float64(0.06829763546753892)),\n",
       " (11533, np.float64(0.06827739820378084)),\n",
       " (10401, np.float64(0.05387582262559459)),\n",
       " (944, np.float64(0.046355650022372775)),\n",
       " (8171, np.float64(0.02921115507265861)),\n",
       " (7944, np.float64(0.01514816089766187)),\n",
       " (1992, np.float64(0.01514816089766187)),\n",
       " (11581, np.float64(0.006131431378182381)),\n",
       " (1840, np.float64(-0.009423695058885087)),\n",
       " (3833, np.float64(-0.01836363481154261)),\n",
       " (2611, np.float64(-0.018692409326563478)),\n",
       " (1277, np.float64(-0.018692409326563478)),\n",
       " (5269, np.float64(-0.01878127311728145)),\n",
       " (11737, np.float64(-0.01878127311728145)),\n",
       " (103, np.float64(-0.026275798700495637)),\n",
       " (2043, np.float64(-0.02654826687242164)),\n",
       " (8795, np.float64(-0.054401997264201)),\n",
       " (5235, np.float64(-0.054401997264201)),\n",
       " (4082, np.float64(-0.054401997264201)),\n",
       " (4396, np.float64(-0.0786243847210959)),\n",
       " (1235, np.float64(-0.08639185943135849)),\n",
       " (12027, np.float64(-0.08753233035360097)),\n",
       " (5864, np.float64(-0.1073326116428204)),\n",
       " (8093, np.float64(-0.15147286230064708)),\n",
       " (324, np.float64(-0.15147286230064708)),\n",
       " (11920, np.float64(-0.15222644939411994)),\n",
       " (2280, np.float64(-0.19250938465669007)),\n",
       " (10161, np.float64(-0.19725703990536672)),\n",
       " (5420, np.float64(-0.2295664679558261)),\n",
       " (1692, np.float64(-0.24236238668397364)),\n",
       " (9951, np.float64(-0.24236238668397364)),\n",
       " (12085, np.float64(-0.24236238668397364)),\n",
       " (2447, np.float64(-0.24236238668397364)),\n",
       " (2680, np.float64(-0.247434960077755)),\n",
       " (2821, np.float64(-0.2597158873670944)),\n",
       " (6955, np.float64(-0.2597158873670944)),\n",
       " (8691, np.float64(-0.2597158873670944)),\n",
       " (1930, np.float64(-0.2597158873670944)),\n",
       " (3946, np.float64(-0.27104716996423733)),\n",
       " (4576, np.float64(-0.27594982799785417)),\n",
       " (2010, np.float64(-0.2777148937323929)),\n",
       " (7670, np.float64(-0.28633238828623364)),\n",
       " (8678, np.float64(-0.28633238828623364)),\n",
       " (4683, np.float64(-0.29410906980240886)),\n",
       " (1756, np.float64(-0.30220349520686235)),\n",
       " (9113, np.float64(-0.31631854730214126)),\n",
       " (3556, np.float64(-0.3191955957408041)),\n",
       " (6668, np.float64(-0.3191955957408041)),\n",
       " (8206, np.float64(-0.3295977056863691)),\n",
       " (3059, np.float64(-0.3295977056863691)),\n",
       " (10347, np.float64(-0.3295977056863691)),\n",
       " (957, np.float64(-0.3438901128532823)),\n",
       " (4612, np.float64(-0.3438901128532823)),\n",
       " (6476, np.float64(-0.3438901128532823)),\n",
       " (11734, np.float64(-0.3438901128532823)),\n",
       " (8730, np.float64(-0.3438901128532823)),\n",
       " (1866, np.float64(-0.3438901128532823)),\n",
       " (10532, np.float64(-0.3438901128532823)),\n",
       " (3010, np.float64(-0.3438901128532823)),\n",
       " (9873, np.float64(-0.3438901128532823)),\n",
       " (11880, np.float64(-0.3438901128532823)),\n",
       " (54, np.float64(-0.3438901128532823)),\n",
       " (6207, np.float64(-0.34647764266939024)),\n",
       " (11657, np.float64(-0.34647764266939024)),\n",
       " (7630, np.float64(-0.34647764266939024)),\n",
       " (10701, np.float64(-0.3673404183465166)),\n",
       " (4666, np.float64(-0.37205388880471196)),\n",
       " (6323, np.float64(-0.37741232363255034)),\n",
       " (8799, np.float64(-0.41972257640068406)),\n",
       " (4239, np.float64(-0.4365438176075053)),\n",
       " (6100, np.float64(-0.47885407037563904)),\n",
       " (7324, np.float64(-0.48325598540014864)),\n",
       " (12240, np.float64(-0.48325598540014864)),\n",
       " (5729, np.float64(-0.5428277661823278)),\n",
       " (6185, np.float64(-0.5428277661823278)),\n",
       " (11187, np.float64(-0.546952373450729)),\n",
       " (9459, 4.8193327992808745),\n",
       " (9419, 4.77980175115531),\n",
       " (4111, 4.754729593571584),\n",
       " (5466, 4.748272282394045),\n",
       " (9445, 4.7217063645205135),\n",
       " (1752, 4.68375436913887),\n",
       " (11106, 4.673915167533409),\n",
       " (517, 4.6658956066246935),\n",
       " (9712, 4.65524557011173),\n",
       " (1264, 4.622711875736649),\n",
       " (5129, 4.612257842248143),\n",
       " (2591, 4.60444829376993),\n",
       " (10017, 4.582893216475742),\n",
       " (6787, 4.559839270338793),\n",
       " (1242, 4.556443582490772),\n",
       " (4291, 4.539540724342327),\n",
       " (7973, 4.532814643218712),\n",
       " (10466, 4.516086319369537),\n",
       " (9232, 4.504449768947819),\n",
       " (12219, 4.478075805190309),\n",
       " (927, 4.473982746352085),\n",
       " (11364, 4.465819034586316),\n",
       " (11765, 4.442311861796139),\n",
       " (8727, 4.400774989749064),\n",
       " (2532, 4.377162849158533),\n",
       " (6634, 4.377162849158533),\n",
       " (5185, 4.372470793992965),\n",
       " (696, 4.360007685027679),\n",
       " (4433, 4.357678757585239),\n",
       " (4665, 4.35535231683904),\n",
       " (1295, 4.353802735873407),\n",
       " (666, 4.300253523707723),\n",
       " (10512, 4.29271097806673),\n",
       " (9844, 4.262061193654594),\n",
       " (9159, 4.2311143775476),\n",
       " (6329, 4.200613731317292),\n",
       " (6342, 4.178381921800589),\n",
       " (1601, 4.176955689607977),\n",
       " (722, 4.169839108493754),\n",
       " (6565, 4.162038825700456),\n",
       " (1096, 4.1318247914406605),\n",
       " (10127, 4.131127358078124),\n",
       " (9641, 4.131127358078124),\n",
       " (8749, 4.120694039948715),\n",
       " (12288, 4.115151122858518),\n",
       " (7429, 4.102733916951033),\n",
       " (3783, 4.097239180167277),\n",
       " (5607, 4.086293742811423),\n",
       " (7142, 4.080162594813422),\n",
       " (2537, 4.074728110620333),\n",
       " (3476, 4.071338903327626),\n",
       " (9268, 4.027786781197694),\n",
       " (660, 4.015890449309338),\n",
       " (424, 3.978678043587201),\n",
       " (9242, 3.9689996483346963),\n",
       " (10266, 3.9485089667460525),\n",
       " (11171, 3.9472353217898197),\n",
       " (5841, 3.9294901791419714),\n",
       " (7659, 3.8981961031798695),\n",
       " (9762, 3.847334047538808),\n",
       " (12169, 3.8155444869884865),\n",
       " (2202, 3.796015009684452),\n",
       " (1976, 3.7877900440463916),\n",
       " (334, 3.773190915774041),\n",
       " (437, 3.771446579417116),\n",
       " (12201, 3.7673827265095055),\n",
       " (11649, 3.7283563431548354),\n",
       " (10473, 3.726085837968589),\n",
       " (9027, 3.716466962750837),\n",
       " (12224, 3.6784830079173454),\n",
       " (1169, 3.6149140878310413),\n",
       " (7478, 3.5763526328588595),\n",
       " (2072, 3.5680104698025015),\n",
       " (6502, 3.55867193340727),\n",
       " (5458, 3.551442354603151),\n",
       " (3995, 3.545782545411204),\n",
       " (8309, 3.4728274642701416),\n",
       " (245, 3.3210836050169217),\n",
       " (8582, 3.270927772461378),\n",
       " (11698, 3.2449072073602054),\n",
       " (3561, 3.2146460157646506),\n",
       " (8791, 3.2053835188808426),\n",
       " (2999, 2.687303578171583),\n",
       " (7703, 2.6805340541638167)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2r_retriever = L2RRetriever(l2r_ranker, doc_text)\n",
    "query = \"condoms\"\n",
    "results_bm25, ranked_doc = l2r_retriever.retrieve(query, top_k=2)\n",
    "ranked_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the RAG Chatbot! Type 'exit' to quit.\n",
      "\n",
      "Chatbot: Condoms are a barrier method of birth control that help prevent the transmission of sexually transmitted infections (STIs) and reduce the chance of unplanned pregnancy. Male condoms are made of latex or other materials and are about 82% effective at preventing pregnancies, while female condoms are around 79% effective. They are highly effective at preventing the transmission of HIV and other STIs when used correctly during each sexual encounter. It's important to use water-based lubricants with condoms, as oil-based lubricants can weaken latex and cause breakage.\n",
      "\n",
      "Document ID: 4129, Score: 0.23464614739350026\n",
      "https://www.healthline.com/health/hiv/risks-sex-without-condoms/\n",
      "Document ID: 5664, Score: 0.23464614739350026\n",
      "https://www.healthline.com/health/birth-control/types-of-birth-control?utm_source=ReadNext\n",
      "Document ID: 4052, Score: 0.2065058708902234\n",
      "https://www.healthline.com/health/healthy-sex/lube-shopping-guide-types\n",
      "Document ID: 7191, Score: 0.19162648007714966\n",
      "https://www.healthline.com/health/healthy-sex/do-condoms-expire?utm_source=ReadNext\n",
      "Document ID: 11671, Score: 0.19162648007714966\n",
      "https://www.healthline.com/health/birth-control-female-condom\n",
      "Document ID: 11542, Score: 0.15860758248297863\n",
      "https://www.healthline.com/health/urinary-tract-infection-adults?utm_source=ReadNext\n",
      "Document ID: 8388, Score: 0.15254568674778193\n",
      "https://www.healthline.com/health/do-spermicide-condoms-work\n",
      "Document ID: 682, Score: 0.1351106020217465\n",
      "https://www.healthline.com/health/healthy-sex/oral-sex-with-a-condom\n",
      "Document ID: 2898, Score: 0.12875195617926338\n",
      "https://www.healthline.com/health/birth-control/barrier-methods-of-birth-control#cervical-caps\n",
      "Document ID: 10267, Score: 0.10993917284483876\n",
      "https://www.healthline.com/health/lambskin-condoms\n"
     ]
    }
   ],
   "source": [
    "rag = RAGSystem(documents, l2r_retriever)\n",
    "print(\"Welcome to the RAG Chatbot! Type 'exit' to quit.\\n\")\n",
    "query = input(\"You:\")\n",
    "answer, ranked_doc = rag.get_answer(query, top_k=2)\n",
    "print(f\"Chatbot: {answer}\\n\")\n",
    "for doc_id, score in ranked_doc[:10]:\n",
    "    print(f\"Document ID: {doc_id}, Score: {score}\")\n",
    "    print(doc_dict[doc_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspellchecker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspellchecker\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQuerySpellCorrector\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Initialize the spell checker\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspellchecker'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
